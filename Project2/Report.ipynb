{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 : Single Agent Continuous Control for the Reacher Task\n",
    "\n",
    "---\n",
    "\n",
    "Author : Rohan Sarkar\n",
    "\n",
    "## 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary libraries and software modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Take Random Actions in the Environment \n",
    "[For testing if environment has been set up properly]\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solve the Reacher Task using DDPG Algorithm\n",
    "\n",
    "The DDPG Algorithm is an actor-critic, model-free, off-policy algorithm based on the deterministic policy gradient that can operate over continuous action spaces proposed in the paper Lillicrap et al, 2015. The main highlights of the algorithm are as follows: \n",
    "- It uses two neural networks -- an actor that learns a policy function from the state and a critic that learns a value function from state-action pairs. This is implemented in Section 4.2.\n",
    "- The algorithm uses experience replay to store experiences of the agent interacting with the environment and subsequently sampling mini-batches of uncorrelated experiences for training. This is implemented in Section 4.3\n",
    "\n",
    "The agent is implemented in Section 4.4 and the code for training the agent is in Section 4.5. Some important implementational details are as follows: \n",
    "- To boost exploration, Ornstein-Uhlenbeck Process is used to add noise to the action output. The goal is to generate temporally correlated exploration for exploration efficiency in physical control problems with inertia. \n",
    "- To stablize the training, soft update is used to update model weights of the **target** actor-critic network from the **local** actor-critic network. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_SOLVED = 30.0    # Moving average score when the environment is considered solved\n",
    "\"\"\"\n",
    "Hyper-parameters for Replay memory and generation of mini-batches of experiences\n",
    "\"\"\"\n",
    "BUFFER_SIZE = int(1e6) # replay buffer size\n",
    "BATCH_SIZE = 128       # minibatch size\n",
    "\"\"\"\n",
    "Hyper-parameters for DDPG Training\n",
    "\"\"\"\n",
    "N_EPISODES = 2000      # maximum number of training episodes\n",
    "N_MAX_TIMESTEPS = 1000 # maximum number of timesteps per episode\n",
    "N_STATE = state_size   # state size for DDPG Agent\n",
    "N_ACTION = action_size # action size for DDPG Agent\n",
    "SEED = 1               # random seed\n",
    "GAMMA = 0.99           # discount factor\n",
    "TAU = 1e-3             # for soft update of target parameters\n",
    "LEARN_INTERVAL = 20    # learning timestep interval\n",
    "LEARN_NUM = 10         # number of learning passes\n",
    "GRAD_CLIPPING = 1.0    # gradient clipping \n",
    "# Ornstein-Uhlenbeck noise parameters\n",
    "OU_MEAN = 0.0\n",
    "OU_SIGMA = 0.2\n",
    "OU_THETA = 0.15\n",
    "# Epsilon decay parameters\n",
    "EPSILON = 1.0         \n",
    "EPSILON_DECAY = 1e-5\n",
    "\"\"\"\n",
    "Hyper-parameters for Actor and Critic\n",
    "\"\"\"\n",
    "LR_ACTOR = 1e-3        # learning rate of the actor\n",
    "LR_CRITIC = 1e-3       # learning rate of the critic\n",
    "ACTOR_NN = [N_STATE, 400, 200, N_ACTION]  # hidden layer sizes of the actor network\n",
    "CRITIC_NN = [N_STATE, 400, 200, N_ACTION] # hidden layer sizes of the critic network\n",
    "WEIGHT_INIT = 5e-3     # initialize weights \n",
    "ACTOR_MODEL_PATH = 'DDPG_Actor.pth'\n",
    "CRITIC_MODEL_PATH = 'DDPG_Critic.pth'\n",
    "# Select GPU for training if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define the Actor and Critic Network Architecture\n",
    "- The **Actor Network** learns the policy function and maps states to actions. It consists of three fully connected layers with batch normalization in the second layer. It uses ReLU activation function for the first two layers and uses tanh in the last layer to ensure that the continuous action values range between [-1, 1].\n",
    "- The **Critic Network** learns the value function and maps (state,action) pairs to Q-values. It also consists of three fully connected layers with batch normalization applied at the first layer. It uses ReLU activation function in all the layers except the last one. The last layer has no activation function so that we get the actual Q-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========================================================================\n",
    "                    Actor Model - Learns Policy Function\n",
    "=========================================================================\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "NN (list) : Number of nodes in neural network layers       \n",
    "\"\"\"\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, NN=ACTOR_NN):\n",
    "        \"\"\"\n",
    "        Initialize parameters and build the actor model.\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(SEED)\n",
    "        self.H1 = nn.Linear(NN[0], NN[1])\n",
    "        self.H1.weight.data.uniform_(*self.initialize(self.H1))\n",
    "        self.H2 = nn.Linear(NN[1], NN[2])\n",
    "        self.H2.weight.data.uniform_(*self.initialize(self.H2))\n",
    "        self.BN = nn.BatchNorm1d(NN[2])\n",
    "        self.O =  nn.Linear(NN[2], NN[3])\n",
    "        self.O.weight.data.uniform_(-1*WEIGHT_INIT, WEIGHT_INIT)\n",
    "        \n",
    "    def initialize(self, layer):\n",
    "        l = 1. / np.sqrt(layer.weight.data.size()[0])\n",
    "        return(-l, l)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Build an actor(policy) network that maps states to actions\n",
    "        tanh activation ensures that the action values range from [-1, 1]\n",
    "        \"\"\"\n",
    "        x = F.relu(self.H1(state))\n",
    "        x = F.relu(self.BN(self.H2(x)))\n",
    "        return torch.tanh(self.O(x))\n",
    "\"\"\"\n",
    "=========================================================================\n",
    "                Critic Model - Learns Value Function\n",
    "=========================================================================\n",
    "Parameters:\n",
    "-----------\n",
    "NN (list) : Number of nodes in neural network layers\n",
    "\"\"\"  \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, NN=CRITIC_NN):\n",
    "        \"\"\"\n",
    "        Initialize parameters and build the critic model.\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(SEED)\n",
    "        self.H1 = nn.Linear(NN[0], NN[1])\n",
    "        self.H1.weight.data.uniform_(*self.initialize(self.H1))\n",
    "        self.BN = nn.BatchNorm1d(NN[1])\n",
    "        self.H2 = nn.Linear(NN[1]+NN[3], NN[2])\n",
    "        self.H2.weight.data.uniform_(*self.initialize(self.H2))\n",
    "        self.O = nn.Linear(NN[2], 1)\n",
    "        self.O.weight.data.uniform_(-1*WEIGHT_INIT, WEIGHT_INIT)\n",
    "        \n",
    "    def initialize(self, layer):\n",
    "        l = 1. / np.sqrt(layer.weight.data.size()[0])\n",
    "        return(-l, l)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        Build the critic (value) network to map (state,action) pairs to Q-values\n",
    "        \"\"\"\n",
    "        x = F.relu(self.BN(self.H1(state)))\n",
    "        x = torch.cat((x, action), dim=1)\n",
    "        x = F.relu(self.H2(x))\n",
    "        return self.O(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Define the Replay Memory \n",
    "- For storing experience tuples\n",
    "- For generating mini-batches of experiences for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========================================================================\n",
    "            Replay Memory to store and sample experiences\n",
    "=========================================================================\n",
    "\"\"\"  \n",
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\"\"\"\n",
    "        self.memory = deque(maxlen=BUFFER_SIZE) \n",
    "        self.experience = namedtuple(\"Experience\", field_names = [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(SEED)\n",
    "        \n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store new experience to replay memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory for training\"\"\"\n",
    "        experiences =  random.sample(self.memory, k=BATCH_SIZE)\n",
    "        S = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        A = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        R = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        NS = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        T = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        return (S, A, R, NS, T)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\"Return the current size of internal memory\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Define and Instantiate the DDPG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "=========================================================================\n",
    "            Ornsten-Uhlenbeck process to add exploration noise\n",
    "=========================================================================\n",
    "\"\"\"                  \n",
    "class ExplorationNoise:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize noise parameters\"\"\"\n",
    "        self.mu = OU_MEAN * np.ones(N_ACTION)\n",
    "        self.theta = OU_THETA\n",
    "        self.sigma = OU_SIGMA\n",
    "        self.seed = random.seed(SEED)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state to mean.\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample\"\"\"\n",
    "        noise = self.theta * (self.mu - self.state) + self.sigma * np.array([random.random() for i in range(len(self.state))])\n",
    "        self.state = self.theta + noise\n",
    "        return self.state\n",
    "\"\"\"\n",
    "=========================================================================\n",
    "    DDPG Agent that interacts with and learns from the environment\n",
    "=========================================================================\n",
    "\"\"\"  \n",
    "class DDPGAgent():   \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a DDPG Agent object.\"\"\"\n",
    "        self.seed = random.seed(SEED)\n",
    "        self.epsilon = EPSILON\n",
    "        \n",
    "        # Initialize the local and target Actor network\n",
    "        self.actor_local = Actor().to(device)\n",
    "        self.actor_target = Actor().to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "        \n",
    "        # Initialize the local and target Critic network\n",
    "        self.critic_local = Critic().to(device)\n",
    "        self.critic_target = Critic().to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC)\n",
    "        \n",
    "        # Initialize the Replay memory\n",
    "        self.memory = ReplayBuffer()\n",
    "        \n",
    "        # Initialize the Ornsten-Uhlenbeck process to add exploration noise\n",
    "        self.OU_noise = ExplorationNoise()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.OU_noise.reset()\n",
    "        \n",
    "    def step(self, S, A, R, NS, T, timestep):\n",
    "        \"\"\" Store experience in replay memory, and randomly sample experiences from buffer for training \"\"\"\n",
    "        self.memory.store(S, A, R, NS, T)\n",
    "        \n",
    "        \"\"\" Learn when enough samples are available in memory \"\"\"\n",
    "        if len(self.memory) > BATCH_SIZE and timestep % LEARN_INTERVAL == 0:\n",
    "            for i in range(LEARN_NUM):\n",
    "                self.learn(self.memory.sample())\n",
    "        \"\"\" epsilon decay \"\"\"\n",
    "        if EPSILON_DECAY > 0:\n",
    "            self.epsilon -= EPSILON_DECAY\n",
    "                \n",
    "    def act(self, S, explore=True):\n",
    "        \"\"\" Returns actions for given state as per currently learnt policy \n",
    "            to which exploration noise is added \"\"\"\n",
    "        state = torch.from_numpy(S).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(S).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if explore:\n",
    "            action += self.epsilon * self.OU_noise.sample()    \n",
    "        return np.clip(action, -1, 1)\n",
    "    \n",
    "    def update(self, local_model, target_model):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target_model = TAU*θ_local_model + (1 - TAU)*θ_target_model\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(TAU*local_param.data + (1.0-TAU)*target_param.data)\n",
    "        \n",
    "    def learn(self, experiences):\n",
    "        \"\"\"Update policy and value parameters using given mini-batch of experience tuples.\n",
    "        Q_targets = r + GAMMA * critic_target(next_state, actor_target(next_state))\n",
    "        \"\"\"\n",
    "        \"\"\" \n",
    "        -----------------------------------------------------------------------------------\n",
    "                                    Unpack mini-batch of experience tuples\n",
    "                    experiences (Tuple[torch.Tensor]): tuple of (S, A, R, NS, T)\n",
    "        -----------------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        S, A, R, NS, T = experiences\n",
    "        \"\"\" \n",
    "        -----------------------------------------------------------------------------------\n",
    "                                Train Critic by minimizing the loss\n",
    "        -----------------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        # get predicted actions for next states and Q values from the target critic model\n",
    "        NA = self.actor_target(NS)\n",
    "        Q_targets_next = self.critic_target(NS, NA)\n",
    "        # compute Q-value targets\n",
    "        Q_targets = R + (GAMMA * Q_targets_next * (1 - T))\n",
    "        # compute and minimize the critic loss\n",
    "        Q_expected = self.critic_local(S, A)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        # gradient clipping for critic \n",
    "        torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), GRAD_CLIPPING)\n",
    "        self.critic_optimizer.step()\n",
    "        \"\"\" \n",
    "        -----------------------------------------------------------------------------------\n",
    "                            Train Actor using the sampled policy gradient\n",
    "        -----------------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        # compute and minimize actor loss\n",
    "        A_pred = self.actor_local(S)\n",
    "        actor_loss = -self.critic_local(S, A_pred).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \"\"\" \n",
    "        -----------------------------------------------------------------------------------\n",
    "                                Update Actor-Critic Target Networks\n",
    "        -----------------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        self.update(self.critic_local, self.critic_target)\n",
    "        self.update(self.actor_local, self.actor_target)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Train the DDPG algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 \tMoving Avg: 1.6\n",
      "Episode 100 \tMoving Avg: 2.7\n",
      "Episode 150 \tMoving Avg: 4.2\n",
      "Episode 200 \tMoving Avg: 5.6\n",
      "Episode 250 \tMoving Avg: 7.8\n",
      "Episode 300 \tMoving Avg: 9.5\n",
      "Episode 350 \tMoving Avg: 10.1\n",
      "Episode 400 \tMoving Avg: 10.6\n",
      "Episode 450 \tMoving Avg: 12.0\n",
      "Episode 500 \tMoving Avg: 13.9\n",
      "Episode 550 \tMoving Avg: 16.0\n",
      "Episode 600 \tMoving Avg: 18.9\n",
      "Episode 650 \tMoving Avg: 21.6\n",
      "Episode 700 \tMoving Avg: 24.3\n",
      "Episode 750 \tMoving Avg: 26.5\n",
      "Episode 800 \tMoving Avg: 26.8\n",
      "Episode 850 \tMoving Avg: 27.2\n",
      "Episode 900 \tMoving Avg: 28.7\n",
      "Episode 950 \tMoving Avg: 29.8\n",
      "\n",
      "Environment solved in 961 episodes.\tAverage score: 30.05\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=========================================================================\n",
    "                        Train the DDPG Algorithm\n",
    "=========================================================================\n",
    "\"\"\"  \n",
    "def train():\n",
    "    \"\"\" \n",
    "    -----------------------------------------------------------------------------------\n",
    "    Instantiate the DDPG Agent\n",
    "    Initialize data-structures to keep track of average-episode scores and moving average\n",
    "    -----------------------------------------------------------------------------------\n",
    "    \"\"\" \n",
    "    agent = DDPGAgent() # instantiate the DDPG agent\n",
    "    mean_score_episode = [] # list of mean scores from each episode\n",
    "    moving_avg_episode = [] # list of moving averages\n",
    "    best_score = -np.inf\n",
    "    scores_last100 = deque(maxlen=100) # mean score from last 100 episodes based on Udacity Project requirements\n",
    "    \"\"\" \n",
    "    -----------------------------------------------------------------------------------\n",
    "    Start learning\n",
    "    -----------------------------------------------------------------------------------\n",
    "    \"\"\" \n",
    "    for i_episode in range(1, N_EPISODES + 1):\n",
    "        \"\"\" Reset environment and agent at the beginning of each episode \"\"\"\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset environment, with training mode ON\n",
    "        scores = np.zeros(num_agents) # initialize score for each agent\n",
    "        states = env_info.vector_observations # get current state \n",
    "        agent.reset() # reset agent\n",
    "        \"\"\" Start episode \"\"\"\n",
    "        for t in range(N_MAX_TIMESTEPS):\n",
    "            \"\"\" Agent interacts with environment \"\"\"\n",
    "            actions = agent.act(states, explore=True) # determine optimal actions\n",
    "            env_info = env.step(actions)[brain_name]  # apply actions to environment and get environment info\n",
    "            next_states = env_info.vector_observations # extract next state information for each agent\n",
    "            rewards = env_info.rewards # extract rewards received for the action taken by each agent\n",
    "            dones = env_info.local_done # Determine terminal state or not\n",
    "            \"\"\" Agent learns from uncorrelated experiences \"\"\"\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t)\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \"\"\" \n",
    "        -----------------------------------------------------------------------------------\n",
    "        Record score stats and print information\n",
    "        -----------------------------------------------------------------------------------\n",
    "        \"\"\" \n",
    "        mean_score_episode.append(np.mean(scores)) # save mean score for each episode\n",
    "        scores_last100.append(mean_score_episode[-1]) # save mean score for last 100 episodes\n",
    "        moving_avg_episode.append(np.mean(scores_last100)) # save moving average\n",
    "        \n",
    "        if i_episode % 50 == 0:\n",
    "            print(\"\\rEpisode {} \\tMoving Avg: {:.1f}\"\\\n",
    "                  .format(i_episode, moving_avg_episode[-1]))\n",
    "        \"\"\" \n",
    "        -----------------------------------------------------------------------------------\n",
    "        Save model weights when the task is solved (moving average score >= 30.0)\n",
    "        -----------------------------------------------------------------------------------\n",
    "        \"\"\" \n",
    "        if moving_avg_episode[-1] >= SCORE_SOLVED:\n",
    "            print(\"\\nEnvironment solved in {:d} episodes.\\tAverage score: {:.2f}\"\\\n",
    "                 .format(i_episode, moving_avg_episode[-1]))\n",
    "            torch.save(agent.actor_local.state_dict(), ACTOR_MODEL_PATH)\n",
    "            torch.save(agent.critic_local.state_dict(), CRITIC_MODEL_PATH)\n",
    "            break        \n",
    "    return mean_score_episode, moving_avg_episode\n",
    "\"\"\" \n",
    "-----------------------------------------------------------------------------------\n",
    "Train and save final model weights\n",
    "-----------------------------------------------------------------------------------\n",
    "\"\"\" \n",
    "scores, avgs = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results and Plot of Rewards\n",
    "As indicated above the enviroment was solved in 961 episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7e468e7b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(np.arange(len(scores)), scores, label='Actual Score ')\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='Moving Average')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode Number')\n",
    "plt.title('Reacher Task using DDPG - Score vs Episode')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ideas for Future Work\n",
    "- Would like to look into ways to speed up training. \n",
    "- Parallelize implementation with multiple agents interacting with the environment independently. More specifically, I would like to explore distributed policy gradient algorithms such as A3C, D4PG. \n",
    "- Replace the Replay Memory with Proritized Experience Replay for better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
